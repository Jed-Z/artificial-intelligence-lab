{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_d(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, g=sigmoid, g_d=sigmoid_d):\n",
    "        self.W_ih = 0.1 * np.random.rand(hidden_dim, input_dim)  # 输入层到隐含层的权重矩阵\n",
    "        self.b_ih = 0.1 * np.random.rand(hidden_dim)             # 输入层到隐含层的偏置\n",
    "        self.W_ho = 0.1 * np.random.rand(out_dim, hidden_dim)    # 隐含层到输出层的权重矩阵\n",
    "        self.b_ho = 0.1 * np.random.rand(out_dim)                # 隐含层到输出层的偏置\n",
    "\n",
    "        self.g = g      # 激活函数\n",
    "        self.g_d = g_d  # 激活函数的梯度\n",
    "        \n",
    "    def feedForward(self, x):\n",
    "        \"\"\"输入x，前馈产生输出。\"\"\"\n",
    "        self.x = x                                      # 输入\n",
    "        self.in_h = self.W_ih @ self.x + self.b_ih      # 隐含层输入\n",
    "        self.out_h = self.g(self.in_h)                  # 隐含层输出\n",
    "        self.in_o = self.W_ho @ self.out_h + self.b_ho  # 输出层输入\n",
    "        self.out_o = self.g(self.in_o)                  # 输出层输出，即网络最终输出\n",
    "        return self.out_o\n",
    "    \n",
    "    def backPropagate(self, target):\n",
    "        \"\"\"反向传播并产生各层敏感度。\"\"\"\n",
    "        self.delta_o = (self.out_o - target) * self.g_d(self.in_o)         # 输出层敏感度\n",
    "        self.delta_h = (self.W_ho.T @ self.delta_o) * self.g_d(self.in_h)  # 隐含层敏感度\n",
    "        \n",
    "    def update(self, rate):\n",
    "        \"\"\"更新各个参数。\"\"\"\n",
    "        self.W_ho -= rate * (np.mat(self.delta_o).T @ np.mat(self.out_h))\n",
    "        self.b_ho -= rate * self.delta_o\n",
    "        self.W_ih -= rate * (np.mat(self.delta_h).T @ np.mat(self.x))\n",
    "        self.b_ih -= rate * self.delta_h\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"对输入特征x进行预测，返回预测结果的下标。\"\"\"\n",
    "        in_h = self.W_ih @ x + self.b_ih\n",
    "        out_h = self.g(in_h)\n",
    "        in_o = self.W_ho @ out_h + self.b_ho\n",
    "        out_o = self.g(in_o)\n",
    "        return out_o.argmax()  # 返回结果中最大值的下标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('dataset/horse-colic-data.csv')\n",
    "data_df['outcome'] = data_df.pop('outcome')\n",
    "for column in data_df.columns:\n",
    "    if column == 'outcome' or data_df[column].var() == 0:\n",
    "        continue\n",
    "#     data_df[column] = zscore(data_df[column])\n",
    "    data_df[column] = (data_df[column] - data_df[column].min()) / (data_df[column].max() - data_df[column].min())  # 归一化\n",
    "# data_df\n",
    "\n",
    "test_df = pd.read_csv('dataset/horse-colic-test.csv')\n",
    "test_df['outcome'] = test_df.pop('outcome')\n",
    "for column in test_df.columns:\n",
    "    if column == 'outcome' or test_df[column].var() == 0:\n",
    "        continue\n",
    "#     test_df[column] = zscore(test_df[column])\n",
    "    test_df[column] = (test_df[column] - test_df[column].min()) / (test_df[column].max() - test_df[column].min())  # 归一化\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 400\n",
    "RATE = 0.01  # 学习率\n",
    "nn = NeuralNetwork(35, 12, 3)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(len(data_df)):\n",
    "        sample = data_df.iloc[i].to_numpy()\n",
    "        x = sample[:-1]\n",
    "        target = np.zeros(3)\n",
    "        target[int(sample[-1])-1] = 1\n",
    "\n",
    "        output = nn.feedForward(x)\n",
    "        nn.backPropagate(target)\n",
    "        nn.update(RATE)\n",
    "        \n",
    "    data_df = data_df.sample(frac=1)  # 打乱样本顺序\n",
    "    RATE *= 0.99  # 减少学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 / 68 = 75.00%\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(test_df)):\n",
    "    sample = test_df.iloc[i].to_numpy()\n",
    "    x, target = sample[:-1], sample[-1]\n",
    "    if nn.predict(x) + 1 == target:\n",
    "        count += 1\n",
    "print('{} / {} = {:.2%}'.format(count, len(test_df), count/len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
