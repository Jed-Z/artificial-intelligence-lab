{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正确地读取数据\n",
    "\n",
    "注意原始数据文件的格式，对其进行正确地处理后读入两个 DataFrame：`adult_data_df` 是训练集， `adult_test_df` 是测试集。DataFrame 中名为“50K”的列为标签（即分类）。\n",
    "\n",
    "读取数据的方法与上个实验（决策树算法）完全相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', '50K']\n",
    "adult_data_df = pd.read_csv('dataset/adult.data', index_col=False, header=None, names=col_names, sep=', ', engine='python')\n",
    "\n",
    "adult_test_df = pd.read_csv('dataset/adult.test', skiprows=[0], index_col=False, header=None, names=col_names, sep=', ', engine='python')\n",
    "adult_test_df['50K'] = adult_test_df['50K'].map(lambda x: x[:-1])  # 去除行末的点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补充缺失值\n",
    "\n",
    "通过对数据的基本观察得知，缺失值所在的列均为离散属性，因此只需要对离散缺失值进行补全即可，本例数据集上无需考虑连续型数据的补全。我采用的方法是使用该列出现次数最多的值（即众数）代替缺失值。\n",
    "\n",
    "补充缺失值的方法与上个实验（决策树算法）完全相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[adult.data]\n",
      "workclass: 1836 missing values are replaced with \"Private\"\n",
      "occupation: 1843 missing values are replaced with \"Prof-specialty\"\n",
      "native-country: 583 missing values are replaced with \"United-States\"\n",
      "-------------------------------\n",
      "[adult.test]\n",
      "workclass: 963 missing values are replaced with \"Private\"\n",
      "occupation: 966 missing values are replaced with \"Prof-specialty\"\n",
      "native-country: 274 missing values are replaced with \"United-States\"\n"
     ]
    }
   ],
   "source": [
    "# 补充缺失值，\n",
    "print('[adult.data]')\n",
    "mode_df = adult_data_df.mode()  # 众数\n",
    "for col in adult_data_df:\n",
    "    if '?' in adult_data_df[col].tolist():\n",
    "        missing_count = adult_data_df[col].value_counts()['?']   # 缺失值的个数\n",
    "        adult_data_df[col] = adult_data_df[col].replace('?', mode_df[col][0])\n",
    "        print('{}: {} missing values are replaced with \"{}\"'.format(col, missing_count, mode_df[col][0]))\n",
    "\n",
    "print('-------------------------------')\n",
    "print('[adult.test]')\n",
    "mode_df = adult_test_df.mode()  # 众数\n",
    "for col in adult_test_df:\n",
    "    if '?' in adult_test_df[col].tolist():\n",
    "        missing_count = adult_test_df[col].value_counts()['?']   # 缺失值的个数\n",
    "        adult_test_df[col] = adult_test_df[col].replace('?', mode_df[col][0])\n",
    "        print('{}: {} missing values are replaced with \"{}\"'.format(col, missing_count, mode_df[col][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测和测试\n",
    "\n",
    "对于测试集中的每个样本，使用朴素贝叶斯方法进行预测，然后与标签比对，并统计准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续型属性\n",
    "continuous_attrs = {'age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'}\n",
    "\n",
    "# 计算概率\n",
    "def probability(df, attr, value):\n",
    "    \"\"\"\n",
    "    计算数据集中某属性为某值的概率。\n",
    "    Params:\n",
    "        df: 数据集。\n",
    "        attr_: 属性名。\n",
    "        value: 属性值。\n",
    "    Return:\n",
    "        对于离散型属性，返回给定属性中值等于给定值的比例；\n",
    "        对于连续型属性，返回对应高斯分布的概率密度函数值。\n",
    "    \"\"\"\n",
    "    attr_series = df[attr]\n",
    "    if attr in continuous_attrs:  # 连续型属性\n",
    "        mean = attr_series.mean()  # 期望\n",
    "        var = attr_series.var()    # 方差\n",
    "        return stats.norm.pdf(value, loc=mean, scale=np.sqrt(var))  # 高斯分布的概率密度\n",
    "    else:  # 离散型属性\n",
    "        return list(attr_series).count(value) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample):\n",
    "    \"\"\"\n",
    "    对一个样本进行预测。\n",
    "    Params:\n",
    "        sample: 待测样本。\n",
    "    Returns:\n",
    "        预测分类结果。\n",
    "    \"\"\"\n",
    "    class_list = ['<=50K', '>50K']  # 所有类别\n",
    "    max_prob = 0\n",
    "    max_class = ''\n",
    "\n",
    "    # 遍历所有可能的分类（本例中只有两种分类）\n",
    "    for class_ in class_list:\n",
    "        class_df = adult_data_df[adult_data_df['50K']==class_]  # 按类划分数据集\n",
    "        prob = adult_data_df['50K'].value_counts().get('<=50K', 0) / len(adult_data_df)  # 初始化为类的先验概率\n",
    "        \n",
    "        for attr in sample.index:\n",
    "            if attr == '50K':  # 标签列不是属性，要跳过\n",
    "                continue\n",
    "            prob *= probability(class_df, attr, sample[attr])  # 累乘每个属性在数据集中出现的概率\n",
    "\n",
    "        if prob >= max_prob:\n",
    "            max_prob = prob\n",
    "            max_class = class_\n",
    "\n",
    "    return max_class  # 返回概率最大的类作为预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "for i in range(len(adult_test_df)):\n",
    "    sample = adult_test_df.iloc[i]\n",
    "    if predict(sample) == sample['50K']:\n",
    "        correct_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率：83.269%\n"
     ]
    }
   ],
   "source": [
    "print('准确率：{:.3%}'.format(correct_count / len(adult_test_df)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
